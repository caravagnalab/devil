% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/main.R
\name{fit_devil}
\alias{fit_devil}
\title{Fit Statistical Model for Count Data}
\usage{
fit_devil(
  input_matrix,
  design_matrix,
  overdispersion = "MOM",
  init_overdispersion = NULL,
  init_beta_rough = FALSE,
  offset = 0,
  size_factors = NULL,
  verbose = FALSE,
  max_iter = 200,
  tolerance = 0.001,
  CUDA = FALSE,
  batch_size = 1024L,
  parallel.cores = 1,
  profiling = FALSE,
  TEST = FALSE
)
}
\arguments{
\item{input_matrix}{A numeric matrix of count data (genes × samples).
Rows represent genes/features, columns represent samples/cells.}

\item{design_matrix}{A numeric matrix of predictor variables (samples × predictors).
Each row corresponds to a sample, each column to a predictor variable.
Must have \code{nrow(design_matrix) == ncol(input_matrix)}.}

\item{overdispersion}{Character or logical. Strategy for estimating overdispersion:
one of \code{"new"}, \code{"I"}, \code{"old"}, \code{"MLE"}, \code{"MOM"}, or
\code{FALSE} to disable overdispersion fitting (Poisson model).
Default: \code{"MOM"}.}

\item{init_overdispersion}{Numeric scalar or \code{NULL}. Initial value for the
overdispersion parameter used as a starting point for the iterative procedures.
If \code{NULL}, an initial value is estimated from the data via \code{estimate_dispersion()}.
Recommended value if specified: \code{100}. Default: \code{NULL}.}

\item{init_beta_rough}{Logial. Whether to initialize betas in a rough but extremely fast way.
Default: \code{FALSE}.}

\item{offset}{Numeric scalar. Value used when computing the offset vector to avoid
numerical issues with zero counts. Default: \code{0}.}

\item{size_factors}{Character string or \code{NULL}. Method for computing normalization
factors to account for different sequencing depths. Options are:
\itemize{
\item \code{NULL} (default):  No normalization (all size factors set to 1)
\item \code{"normed_sum"}: Geometric mean normalization
\item \code{"psinorm"}: Psi-normalization
\item \code{"edgeR"}: edgeR TMM method
}}

\item{verbose}{Logical. Whether to print progress messages during execution.
Default: \code{FALSE}.}

\item{max_iter}{Integer. Maximum number of iterations for parameter optimization
(both beta and overdispersion routines). Default: \code{200}.}

\item{tolerance}{Numeric. Convergence criterion for parameter optimization.
Default: \code{1e-3}.}

\item{CUDA}{Logical. Whether to use GPU acceleration (requires CUDA support and
a compiled \code{beta_fit_gpu()} implementation). Default: \code{FALSE}.}

\item{batch_size}{Integer. Number of genes to process per batch in GPU mode.
Only relevant if \code{CUDA = TRUE}. Default: \code{1024}.}

\item{parallel.cores}{Integer or \code{NULL}. Number of CPU cores for parallel
processing with \code{parallel::mclapply}. If \code{NULL}, uses all available cores.
Default: \code{1}.}

\item{profiling}{Logical. If \code{TRUE}, prints timing information for major
steps (size factors, offset computation, initial dispersion, beta fit, theta fit).
Useful for performance profiling. Default: \code{FALSE}.}

\item{TEST}{Logical. If \code{TRUE}, enables GPU validation mode. When CUDA is enabled,
this will compute ground truth results on CPU and compare with GPU results, reporting
correlations and differences for init_beta, k (dispersion), theta (overdispersion),
and final beta coefficients. Default: \code{FALSE}.}
}
\value{
A list containing:
\describe{
\item{beta}{Matrix of fitted coefficients (genes × predictors).}
\item{overdispersion}{Vector of fitted overdispersion parameters (one per gene).}
\item{iterations}{List with elements \code{beta_iters} and \code{theta_iters}
giving the number of iterations used for each gene.}
\item{size_factors}{Vector of computed size factors (one per sample).}
\item{offset_vector}{Vector of offset values used in the model (length = number of samples).}
\item{design_matrix}{Input design matrix (as provided, possibly coerced to numeric matrix).}
\item{input_matrix}{Input count matrix (as provided, possibly coerced to numeric matrix).}
\item{input_parameters}{List of used parameter values
(\code{max_iter}, \code{tolerance}, \code{parallel.cores}).}
}
}
\description{
Fits a statistical model to count data, particularly designed for RNA-seq
data analysis. The function estimates regression coefficients (beta),
gene-wise overdispersion parameters, and normalizes data using size factors.
It supports both CPU and (optionally) GPU-based computation with
parallel processing capabilities.
}
\details{
The function implements a negative binomial regression model with
the following steps:
\enumerate{
\item Computes size factors for data normalization (if requested)
\item Initializes model parameters including beta coefficients and overdispersion
\item Fits the regression coefficients using either CPU (parallel) or GPU computation
\item Optionally fits/updates overdispersion parameters using one of several strategies
}

The model fitting process uses iterative optimization with configurable convergence
criteria and maximum iterations. For large datasets, the GPU implementation processes
genes in batches for improved memory efficiency.
}
\section{Size Factor Methods}{

Three normalization methods are available when \code{size_factors} is a character string:
\itemize{
\item \code{"normed_sum"} (default): Geometric mean normalization based on library sizes.
Fast and works well for most datasets.
\item \code{"psinorm"}: Psi-normalization using Pareto distribution MLE.
More robust to highly variable genes.
\item \code{"edgeR"}: edgeR's TMM with singleton pairing method.
Requires the edgeR package from Bioconductor.
}
If \code{size_factors = NULL}, no normalization is performed and all size factors are set to 1.
}

\section{Overdispersion Strategies}{

The \code{overdispersion} argument controls how gene-wise overdispersion is handled:
\itemize{
\item \code{"old"} or \code{"MLE"}: Overdispersion is fit via the original (legacy) NB
MLE-based procedure (with Cox–Reid adjustment inside \code{fit_dispersion()}).
\item \code{"new"} or \code{"I"}: Overdispersion is fit via the new iterative NB
routine implemented in \code{fit_overdispersion_cppp()}, typically faster and
more stable for large single-cell datasets.
\item \code{"MOM"}: Overdispersion is estimated using a method-of-moments approach via
\code{estimate_mom_dispersion_cpp()}, which is cheap and provides a rough
dispersion estimate.
\item \code{FALSE}: Disable overdispersion fitting and use a Poisson model
(overdispersion fixed to 0).
}
}

\examples{
## Example: fit a simple two-group model
set.seed(1)

# Simulate a small counts matrix (genes x cells)
counts <- matrix(
    rnbinom(1000, mu = 0.2, size = 1),
    nrow = 100, ncol = 10
)
rownames(counts) <- paste0("gene", seq_len(nrow(counts)))

# Two-group design (no intercept)
group <- factor(rep(c("A", "B"), each = 5))
design <- model.matrix(~ 0 + group)
colnames(design) <- levels(group)

# Fit the model
fit <- fit_devil(
    input_matrix  = counts,
    design_matrix = design,
    size_factors  = "normed_sum",
    verbose       = TRUE
)

}
